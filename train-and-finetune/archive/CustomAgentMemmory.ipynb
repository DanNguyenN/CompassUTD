{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    #!pip install langchain google-cloud-aiplatform rich\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compass_prompt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "You should answer the following questions with up-to-date information. You have access to the following tools:\"\"\"\n",
    "\n",
    "format_instruction = \"\"\"You must use the following format for all responses or your response will be considered incorrect:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action in a single sentence.\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times but Question should only appear once)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "If you do not know the answer, you can say so.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\n",
    "\"\"\"\n",
    "zero_shot_prompt = {\n",
    "    \"prefix\": prefix,\n",
    "    \"format_instruction\": format_instruction,\n",
    "    \"suffix\": suffix,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compass_toolkit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from typing import TYPE_CHECKING, List, Optional\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from langchain.tools.base import BaseTool\n",
    "from langchain.agents.agent_toolkits.base import BaseToolkit\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForToolRun\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tool_microservice_url = str(os.getenv(\"TOOL_URL\"))\n",
    "\n",
    "\n",
    "class CompassToolkit(BaseToolkit):\n",
    "    def get_tools(self) -> List[BaseTool]:\n",
    "        \"\"\"Get the tools in the toolkit.\"\"\"\n",
    "        return [\n",
    "            ProfessorSearchResults(),\n",
    "            CoursesSearchResults(),\n",
    "            DegreesSearchResults(),\n",
    "            GeneralSearchResults(),\n",
    "        ]\n",
    "\n",
    "\n",
    "def request_error_handler(url: str, params={}) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, params)\n",
    "        response.raise_for_status()  # Raise an HTTPError if the status code is not in the 200 range\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "\n",
    "class ProfessorSearchResults(BaseTool):\n",
    "    name = \"get_professor_rating_and_classes_taught\"\n",
    "    description = (\n",
    "        \"a search engine on professor of UT Dallas on RateMyProfessor database\"\n",
    "        \"useful for when you need to answer questions about professors ratings, difficulty, and class taught.\"\n",
    "        \"will not return contact information, use the general_search tool for that.\"\n",
    "        \"Input should be a First, Last or Full name of the professor without greeting prefix\"\n",
    "        \"Return will be full name, courses taught, overall rating, and difficulty rating\"\n",
    "    )\n",
    "\n",
    "    def _run(\n",
    "        self, name: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/get-professor-rmp/{name}\"\n",
    "        return request_error_handler(url)\n",
    "\n",
    "    async def _arun(\n",
    "        self, name: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        raise NotImplementedError(\"does not support async yet\")\n",
    "\n",
    "\n",
    "class CoursesSearchResults(BaseTool):\n",
    "\n",
    "    name = \"course_search\"\n",
    "    description = (\n",
    "        \"a search engine on course database of UT Dallas\"\n",
    "        \"useful for when you need to search for answer about courses.\"\n",
    "        \"Input should be a search query\"\n",
    "        \"Return will be multiple results with course title and snippet\"\n",
    "    )\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/get-possible-courses/{query}\"\n",
    "        return request_error_handler(url)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        raise NotImplementedError(\"does not support async yet\")\n",
    "\n",
    "\n",
    "class DegreesSearchResults(BaseTool):\n",
    "\n",
    "    name = \"college_degree_search\"\n",
    "    description = (\n",
    "        \"a search engine on college degree database of UT Dallas\"\n",
    "        \"useful for when you need to search for answer about college degrees.\"\n",
    "        \"Input should be a search query\"\n",
    "        \"Return will be multiple results with title, and snippet of the degree\"\n",
    "    )\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/get-degree-info/{query}\"\n",
    "        return request_error_handler(url)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        raise NotImplementedError(\"does not support async yet\")\n",
    "\n",
    "\n",
    "class GeneralSearchResults(BaseTool):\n",
    "    name = \"general_search\"\n",
    "    description = (\n",
    "        \"a search engine for general information about UT Dallas\"\n",
    "        \"useful for when you need to search for answer related to professor(s), staff(s), school(s), department(s), and UT Dallas\"\n",
    "        \"Searching for courses or college degrees are discouraged as there are better tools\"\n",
    "        \"Input should be a search query\"\n",
    "        \"Return will be multiple results with title, link and snippet\"\n",
    "    )\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/search/{query}\"\n",
    "        return request_error_handler(url)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        raise NotImplementedError(\"does not support async yet\")\n",
    "\n",
    "\n",
    "class DictionaryRun(BaseTool):\n",
    "    name = \"get_definition_of_word\"\n",
    "    description = \"a dictionary for simple word\" \"Input should be word or phrases\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/dictionary/{query}\"\n",
    "        return request_error_handler(url)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        url = f\"https://{tool_microservice_url}/dictionary/{query}\"\n",
    "        return await request_error_handler(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compass_agent.py \n",
    "### Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, AgentExecutor\n",
    "from langchain.experimental.plan_and_execute import (\n",
    "    PlanAndExecute,\n",
    "    load_agent_executor,\n",
    "    load_chat_planner,\n",
    ")\n",
    "\n",
    "from langchain import LLMChain\n",
    "\n",
    "# from compass_prompt import zero_shot_prompt #! uncomment this line when using compass_prompt.py\n",
    "\n",
    "\n",
    "class CompassAgent:\n",
    "    def __init__(self, llm, tools, memory) -> None:\n",
    "        self.__init_plan_and_execute__(llm, tools, memory)\n",
    "\n",
    "    def __init_zero_shot__(self, llm, tools, memory) -> None:\n",
    "        self.prompt = ZeroShotAgent.create_prompt(\n",
    "            tools=tools,\n",
    "            prefix=zero_shot_prompt[\"prefix\"],\n",
    "            suffix=zero_shot_prompt[\"suffix\"],\n",
    "            format_instructions=zero_shot_prompt[\"format_instruction\"],\n",
    "            input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "        )\n",
    "        llm_chain = LLMChain(llm=llm, prompt=self.prompt)\n",
    "        agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "        self.agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            verbose=True,\n",
    "            memory=memory,\n",
    "            handle_parsing_errors=False,\n",
    "        )\n",
    "\n",
    "    def __init_plan_and_execute__(self, llm, tools, memory) -> None:\n",
    "        planner = load_chat_planner(llm=llm)\n",
    "        executor = load_agent_executor(llm=llm, tools=tools, verbose=False)\n",
    "        self.agent_chain = PlanAndExecute(\n",
    "            planner=planner, executor=executor, memory=memory\n",
    "        )\n",
    "\n",
    "    def _run(self, input: str) -> str:\n",
    "        try:\n",
    "            return self.agent_chain.run(input=input)\n",
    "        except ValueError as e:\n",
    "            return self.error_handler(e)\n",
    "\n",
    "    async def _arun(self, input: str) -> str:\n",
    "        try:\n",
    "            return self.agent_chain.arun(input=input)\n",
    "        except ValueError as e:\n",
    "            return self.error_handler(e)\n",
    "\n",
    "    def error_handler(self, e):\n",
    "        response = str(e)\n",
    "        prefix = \"Could not parse LLM output: `\"\n",
    "        if not response.startswith(prefix):\n",
    "            raise e\n",
    "        response = response.removeprefix(prefix).removesuffix(\"`\")\n",
    "        return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compass_inference.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# from compass_agent import CompassAgent #! uncomment this line when using compass_agent.py\n",
    "# from compass_toolkit import CompassToolkit #! uncomment this line when using compass_toolkit.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.memory import ConversationBufferMemory, MongoDBChatMessageHistory\n",
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class CompassInference:\n",
    "    def __init__(self) -> None:\n",
    "        aiplatform.init(project=\"aerobic-gantry-387923\", location=\"us-central1\")\n",
    "        self.vertex = VertexAI(\n",
    "                                model_name = \"text-bison\",\n",
    "                                temperature=0, \n",
    "                               max_tokens=1024, \n",
    "                               top_p=0.95, top_k=40)\n",
    "        self.tools = CompassToolkit().get_tools()\n",
    "\n",
    "    def _run(self, user_message: str, mongodb_past_history) -> str:\n",
    "\n",
    "        clone_memory = self.clone_message_history(mongodb_past_history)\n",
    "        agent = CompassAgent(llm=self.vertex, tools=self.tools, memory=clone_memory)\n",
    "\n",
    "        bot_message = agent._run(user_message)\n",
    "\n",
    "        return bot_message\n",
    "\n",
    "    def clone_message_history(\n",
    "        self, message_history: MongoDBChatMessageHistory\n",
    "    ) -> ConversationBufferMemory:\n",
    "        memory_clone = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "        try:\n",
    "            for message in message_history.messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    memory_clone.chat_memory.add_ai_message(message.content)\n",
    "                elif isinstance(message, HumanMessage):\n",
    "                    memory_clone.chat_memory.add_user_message(message.content)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        return memory_clone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    f\"mongodb+srv://{str(os.getenv('MONGODB_LOGIN'))}@compass-utd.gc5s9o8.mongodb.net\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Rerun this cell to reset memory\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "message_history = MongoDBChatMessageHistory(\n",
    "    # make random session id\n",
    "    connection_string=connection_string,\n",
    "    session_id=\"test_\".join(\n",
    "        random.choices(string.ascii_uppercase + string.digits, k=5)\n",
    "    ),\n",
    ")\n",
    "\n",
    "agent = CompassInference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent._run(\n",
    "    \"What is the different between Math 2417 and Math 2413\", message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
